{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # https://www.house.gov/representatives\n",
    "# # I want to scrape the names of all the representatives from New York (state).\n",
    "\n",
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# url = 'https://www.house.gov/representatives'\n",
    "# response = requests.get(url)\n",
    "# print(response.status_code)\n",
    "# soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# # print(soup.prettify())\n",
    "\n",
    "# #by-state > div > div > div.view-content (contains tables of representatives by state)\n",
    "# # <caption id=\"state-alabama\">Alabama </caption> (state looks like this)\n",
    "# #housegov_reps_by_state-block_default-883106430 > tbody > tr:nth-child(1) is the first row of the table (a single representative from the first state)\n",
    "\n",
    "# # I want to find the table that contains the representatives from New York\n",
    "\n",
    "# # Locate the caption for New York using a text match\n",
    "# ny_caption = soup.find('caption', string=lambda text: 'New York' in text)\n",
    "# if ny_caption:\n",
    "#     # Get the parent table of this caption\n",
    "#     ny_table = ny_caption.find_parent('table')\n",
    "#     if ny_table:\n",
    "#         representatives = ny_table.find_all('tr')\n",
    "        \n",
    "#         # Print each representative's name assuming the name is in the first td\n",
    "#         for rep in representatives[1:]:  # skip the header row if present\n",
    "#             # for all td elements in the row, put all td elements in a list\n",
    "#             tds = rep.find_all('td')\n",
    "#             # strip and put into a list\n",
    "#             print([td.text.strip() for td in tds])\n",
    "#     else:\n",
    "#         print(\"No table found for New York\")\n",
    "# else:\n",
    "#     print(\"Couldn't find the New York section on the page\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\"\"\"\n",
    "GET DATA\n",
    "\"\"\"\n",
    "url = 'https://www.house.gov/representatives'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "# print(soup.prettify())\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "PARSE DATA\n",
    "\"\"\"\n",
    "state_section = soup.find('a', {'href': '#by-state'})\n",
    "if state_section is None:\n",
    "    print(\"Couldn't find the section for states\")\n",
    "    exit()\n",
    "\n",
    "# Find all caption elements which typically contain state names\n",
    "captions = soup.find_all('caption')\n",
    "\n",
    "# Prepare a list to hold all representative data\n",
    "all_reps = []\n",
    "\n",
    "# Iterate over each state's caption\n",
    "for caption in captions:\n",
    "    state = caption.get_text(strip=True)\n",
    "    table = caption.find_parent('table')\n",
    "    if table:\n",
    "        headers = [th.get_text(strip=True) for th in table.find('tr').find_all('th')]\n",
    "        rows = table.find_all('tr')[1:]  # Skipping the header row\n",
    "\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) == len(headers):  # Ensuring each row has the correct number of columns\n",
    "                rep_data = {'State': state}\n",
    "                rep_data.update({headers[i]: cols[i].get_text(strip=True) for i in range(len(cols))})\n",
    "                all_reps.append(rep_data)\n",
    "\n",
    "\"\"\"\n",
    "CONVERT DATA TO DATAFRAME\n",
    "\"\"\"\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df_reps = pd.DataFrame(all_reps)\n",
    "\n",
    "# df should only contain first half of the rows\n",
    "df_reps = df_reps.head(int(len(df_reps)/2))\n",
    "\n",
    "\"\"\"\n",
    "ALTER DATAFRAME FOR ANALYSIS\n",
    "\"\"\"\n",
    "# Split the Name column into separate First Name and Last Name columns\n",
    "df_reps[['first_name', 'last_name']] = df_reps['Name'].str.split(', ', expand=True)\n",
    "\n",
    "# Drop the original Name column\n",
    "df_reps.drop(columns=['Name'], inplace=True)\n",
    "\n",
    "# Create a full_name column by concatenating first_name and last_name\n",
    "df_reps['full_name'] = df_reps['first_name'] + ' ' + df_reps['last_name']\n",
    "\n",
    "# Split Committee assignments into separate columns; find max number of committees for any representative\n",
    "max_cols = df_reps['Committee Assignment'].str.split('|').apply(len).max()\n",
    "\n",
    "# Create new columns for each committee\n",
    "for i in range(max_cols):\n",
    "    df_reps[f'committee_{i+1}'] = df_reps['Committee Assignment'].str.split('|').str[i]\n",
    "\n",
    "# Drop the original Committee Assignment column\n",
    "df_reps.drop(columns=['Committee Assignment'], inplace=True)\n",
    "\n",
    "\"\"\"\n",
    "SAVE DATA TO CSV\n",
    "\"\"\"\n",
    "# Display the DataFrame\n",
    "# print(df_reps)\n",
    "\n",
    "# check if inputs folder exists; if not, create it\n",
    "DATA_PATH = '../../data'\n",
    "\n",
    "if not os.path.exists(DATA_PATH+'/inputs'):\n",
    "    os.makedirs(DATA_PATH+'/inputs')\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "df_reps.to_csv(DATA_PATH+'/inputs/house_committees.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# url = \"https://senate.gov/general/committee_assignments/assignments.htm\"\n",
    "# response = requests.get(url)\n",
    "# print(response.status_code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
